# AGENTS.md - Simulation Engine (`src/simulation/`)

This document provides guidelines for developing components related to scenario generation and stress testing within the `src/simulation/` directory. It is an extension of the guidelines in `src/AGENTS.md` and the root `AGENTS.md`.

## 1. `ScenarioGenerator`

*   **Purpose:** Responsible for creating different types of scenarios that can be applied to a portfolio for stress testing.
*   **Scenario Definition:**
    *   Support various types of shocks:
        *   Feature-level shocks (multiplicative, additive, override) to raw input features of companies or loans.
        *   Macroeconomic variable shocks (if such variables are integrated into models or as contextual factors).
        *   (Future) More complex, systemic shocks based on KG relationships or predefined narratives.
    *   Scenarios should be clearly named and described.
*   **Input Data:** The `ScenarioGenerator` will typically take a baseline portfolio dataset (e.g., a list of dictionaries or a DataFrame representing entities and their features before shocks) as input.
*   **Output Data:** The output should be the "shocked" portfolio dataset, with relevant features modified according to the scenario definition. The structure of the output should be consistent with the input, allowing it to be fed into the `StressTester`.
*   **HITL in Scenario Definition:**
    *   Design the service to allow scenario parameters to be loaded from a configurable source (e.g., a JSON file). This enables analysts to define or tweak scenarios without code changes.
    *   (Future) Consider interfaces for analysts to define more complex, multi-step, or conditional scenarios.
*   **Extensibility:** Allow for easy addition of new shock types or scenario generation methodologies.

## 2. `StressTester`

*   **Purpose:** Applies scenarios (generated by `ScenarioGenerator`) to a portfolio and evaluates the impact on risk metrics (PD, LGD, EL).
*   **Core Logic:**
    *   Takes a "shocked" portfolio dataset as input.
    *   For each entity in the shocked portfolio:
        *   Re-calculates PD using the `PDModel` with the shocked features.
        *   Re-calculates LGD using the `LGDModel` with the shocked features.
        *   Computes the stressed Expected Loss (EL).
    *   Compares stressed risk metrics against baseline (pre-shock) metrics to quantify the impact.
*   **Model Interaction:**
    *   The `StressTester` MUST use the production/specified versions of `PDModel` and `LGDModel` for re-calculating risk metrics. It should not have its own embedded models.
    *   Ensure that the feature engineering logic used internally by `PDModel` and `LGDModel` (when they predict) is correctly applied to the shocked features.
*   **Output Format:**
    *   The output should clearly present both baseline and stressed risk metrics, along with the delta or percentage change.
    *   Provide both individual entity-level impacts and aggregated portfolio-level impacts.
    *   The output should be structured for easy consumption by analysis notebooks or future UI components (e.g., a list of dictionaries or a DataFrame).
*   **HITL in Impact Assessment:**
    *   The results from `StressTester` will be reviewed by analysts. Ensure the output is clear and provides enough detail for them to understand how the scenario affected different parts of the portfolio.
    *   (Future) Analysts might flag certain stress test results as counter-intuitive or requiring further investigation, providing feedback on model sensitivity or scenario plausibility.
*   **Performance:** For large portfolios and many scenarios, stress testing can be computationally intensive. Consider performance implications in the design.

## 3. General Simulation Guidelines

*   **Clarity of Assumptions:** Clearly document any assumptions made in scenario definitions or the stress testing process.
*   **Reproducibility:** Ensure that simulations are reproducible. If randomness is involved (e.g., in generating certain types of scenarios), allow for setting random seeds.
*   **Modularity:** Keep `ScenarioGenerator` and `StressTester` as distinct modules with clear responsibilities.
*   **Integration with Risk Map:** The results of stress tests are a key input to the overall risk assessment and should be viewable within the context of the "Probability Map" (e.g., showing how an entity's position on the map shifts under stress).

By following these guidelines, the simulation components can provide valuable insights into portfolio resilience and the potential impact of adverse conditions, forming a critical part of the AI HITL Risk Control framework.
