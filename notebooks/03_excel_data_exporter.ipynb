{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidated Data Exporter to Excel\n",
    "\n",
    "This notebook gathers key data tables generated by the credit risk analysis system and exports them into a single Excel file (`consolidated_data_export.xlsx`) with multiple sheets. It also displays previews of these tables within the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json # For pretty printing dicts if needed, not strictly for excel\n",
    "import numpy as np # For synthetic data generation\n",
    "import logging\n",
    "\n",
    "# Project-specific imports (adjust paths if notebook is run from a different CWD)\n",
    "# Assuming notebook is in 'notebooks/' and project root is parent.\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append('../') # Add project root to path\n",
    "\n",
    "from src.data_management.knowledge_base import KnowledgeBaseService, IndustrySector, Currency, CollateralType\n",
    "from src.data_management.ontology import CorporateEntity # For type hinting if needed\n",
    "from src.risk_models.pd_model import PDModel\n",
    "from src.risk_models.lgd_model import LGDModel\n",
    "from src.mlops.model_registry import ModelRegistry\n",
    "from src.data_management.knowledge_graph import KnowledgeGraphService # kg_service needed for RiskMapService\n",
    "from src.risk_map.risk_map_service import RiskMapService\n",
    "\n",
    "# Configure basic logging for the notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('ExcelExporterNotebook')\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = Path(\"../output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logger.info(\"Setup complete. Modules imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing services and loading models...\")\n",
    "kb_service = KnowledgeBaseService()\n",
    "\n",
    "# Load PD Model (with fallback to training for demo robustness)\n",
    "registry = ModelRegistry()\n",
    "pd_model_path_str = registry.get_production_model_path(\"PDModel\")\n",
    "pd_model_instance = PDModel(model_path=Path(pd_model_path_str) if pd_model_path_str else None)\n",
    "if not pd_model_instance.load_model():\n",
    "    logger.warning(\"PD Model could not be loaded from registry or default path. Training a new one for demo...\")\n",
    "    if kb_service.get_all_loans(limit=1): # Check if data is available\n",
    "        train_metrics_pd = pd_model_instance.train(kb_service) # This will also register it\n",
    "        if \"error\" not in train_metrics_pd:\n",
    "            logger.info(f\"Newly trained PD Model. Metrics: {train_metrics_pd}\")\n",
    "            latest_pd_versions = registry.list_models(\"PDModel\")\n",
    "            if latest_pd_versions:\n",
    "                registry.update_model_status(\"PDModel\", latest_pd_versions[0]['model_version'], \"production\")\n",
    "                logger.info(f\"Newly trained PD Model {latest_pd_versions[0]['model_version']} set to production for this session.\")\n",
    "        else:\n",
    "            logger.error(f\"Failed to train PD Model for demo: {train_metrics_pd.get('error', 'Unknown error')}\")\n",
    "    else:\n",
    "        logger.error(\"ERROR: KB data not loaded, cannot train PD Model for demo.\")\n",
    "else:\n",
    "    logger.info(f\"PD Model loaded successfully from: {pd_model_instance.model_path}\")\n",
    "\n",
    "# Load LGD Model (with fallback to training)\n",
    "lgd_model_path_str = registry.get_production_model_path(\"LGDModel\")\n",
    "lgd_model_instance = LGDModel(model_path=Path(lgd_model_path_str) if lgd_model_path_str else None)\n",
    "if not lgd_model_instance.load_model():\n",
    "    logger.warning(\"LGD Model could not be loaded from registry or default path. Training a new one for demo...\")\n",
    "    if kb_service.get_all_loans(limit=1): # Check if data is available\n",
    "        train_metrics_lgd = lgd_model_instance.train(kb_service) # This will also register it\n",
    "        if \"error\" not in train_metrics_lgd:\n",
    "            logger.info(f\"Newly trained LGD Model. Metrics: {train_metrics_lgd}\")\n",
    "            latest_lgd_versions = registry.list_models(\"LGDModel\")\n",
    "            if latest_lgd_versions:\n",
    "                registry.update_model_status(\"LGDModel\", latest_lgd_versions[0]['model_version'], \"production\")\n",
    "                logger.info(f\"Newly trained LGD Model {latest_lgd_versions[0]['model_version']} set to production for this session.\")\n",
    "        else:\n",
    "            logger.error(f\"Failed to train LGD Model for demo: {train_metrics_lgd.get('error', 'Unknown error')}\")\n",
    "    else:\n",
    "        logger.error(\"ERROR: KB data not loaded, cannot train LGD Model for demo.\")\n",
    "else:\n",
    "    logger.info(f\"LGD Model loaded successfully from: {lgd_model_instance.model_path}\")\n",
    "\n",
    "kg_service = KnowledgeGraphService(kb_service=kb_service)\n",
    "risk_map_service = RiskMapService(kb_service=kb_service, pd_model=pd_model_instance, lgd_model=lgd_model_instance, kg_service=kg_service)\n",
    "\n",
    "logger.info(\"Services and models initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Portfolio Risk Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generating Portfolio Risk Overview...\")\n",
    "portfolio_overview_data = risk_map_service.generate_portfolio_risk_overview()\n",
    "portfolio_overview_df = pd.DataFrame(portfolio_overview_data)\n",
    "logger.info(f\"Portfolio Overview Table Shape: {portfolio_overview_df.shape}\")\n",
    "if not portfolio_overview_df.empty:\n",
    "    display(portfolio_overview_df.head())\n",
    "else:\n",
    "    logger.warning(\"Portfolio Overview DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Risk Summary by Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generating Risk Summary by Sector...\")\n",
    "sector_summary_data = risk_map_service.get_risk_summary_by_sector(portfolio_overview_data)\n",
    "sector_summary_df = pd.DataFrame.from_dict(sector_summary_data, orient='index')\n",
    "logger.info(f\"Sector Summary Table Shape: {sector_summary_df.shape}\")\n",
    "if not sector_summary_df.empty:\n",
    "    display(sector_summary_df.head())\n",
    "else:\n",
    "    logger.warning(\"Sector Summary DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Risk Summary by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generating Risk Summary by Country...\")\n",
    "country_summary_data = risk_map_service.get_risk_summary_by_country(portfolio_overview_data)\n",
    "country_summary_df = pd.DataFrame.from_dict(country_summary_data, orient='index')\n",
    "logger.info(f\"Country Summary Table Shape: {country_summary_df.shape}\")\n",
    "if not country_summary_df.empty:\n",
    "    display(country_summary_df.head())\n",
    "else:\n",
    "    logger.warning(\"Country Summary DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample Company Data (from Knowledge Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Fetching company data from Knowledge Base...\")\n",
    "all_companies_full_obj = kb_service.get_all_companies()\n",
    "companies_data_for_excel = [comp.model_dump(mode='json') for comp in all_companies_full_obj]\n",
    "companies_df = pd.DataFrame(companies_data_for_excel)\n",
    "\n",
    "# Convert list-like fields to comma-separated strings for better Excel view\n",
    "list_cols_to_convert = ['subsidiaries', 'suppliers', 'customers', 'loan_agreement_ids', 'financial_statement_ids']\n",
    "for col in list_cols_to_convert:\n",
    "    if col in companies_df.columns:\n",
    "        companies_df[col] = companies_df[col].apply(lambda x: ', '.join(x) if isinstance(x, list) and x else None)\n",
    "\n",
    "logger.info(f\"Companies Table Shape: {companies_df.shape}\")\n",
    "if not companies_df.empty:\n",
    "    display(companies_df.head())\n",
    "else:\n",
    "    logger.warning(\"Companies DataFrame from KB is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Illustrative Synthetic Equities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_equities(num_entities=10):\n",
    "    data = []\n",
    "    sectors = [s.value for s in IndustrySector] + [\"Consumer Discretionary\", \"Healthcare\", \"Real Estate\"]\n",
    "    for i in range(num_entities):\n",
    "        beta = np.random.normal(1.0, 0.3)\n",
    "        data.append({\n",
    "            'entity_id': f\"EQ_COMP{i:03d}\",\n",
    "            'name': f\"Equity Example Co {i+1}\",\n",
    "            'sector': np.random.choice(sectors),\n",
    "            'simulated_market_cap': np.random.lognormal(mean=np.log(10000), sigma=1.5) * 1_000_000, # In Millions\n",
    "            'simulated_beta': round(beta, 2),\n",
    "            'simulated_expected_return': round(0.02 + beta * 0.05, 4), # risk_free + beta * market_premium\n",
    "            'simulated_volatility': round(np.random.uniform(0.15, 0.60), 4)\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "logger.info(\"Generating Illustrative Synthetic Equities Data...\")\n",
    "synthetic_equities_df = generate_synthetic_equities()\n",
    "logger.info(f\"Synthetic Equities Table Shape: {synthetic_equities_df.shape}\")\n",
    "display(synthetic_equities_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Illustrative Synthetic Commodities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_commodities(num_assets=4):\n",
    "    commodities = [\"Crude Oil\", \"Gold\", \"Copper\", \"Corn\"]\n",
    "    data = []\n",
    "    weights = np.random.dirichlet(np.ones(num_assets), size=1)[0]\n",
    "    for i, name in enumerate(commodities[:num_assets]):\n",
    "        data.append({\n",
    "            'asset_id': f\"COMM_{name.replace(' ', '_').upper()[:4]}\",\n",
    "            'name': name,\n",
    "            'simulated_expected_return': round(np.random.uniform(0.03, 0.08), 4),\n",
    "            'simulated_volatility': round(np.random.uniform(0.10, 0.40), 4),\n",
    "            'simulated_weight_in_portfolio': round(weights[i], 4)\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "logger.info(\"Generating Illustrative Synthetic Commodities Data...\")\n",
    "synthetic_commodities_df = generate_synthetic_commodities()\n",
    "logger.info(f\"Synthetic Commodities Table Shape: {synthetic_commodities_df.shape}\")\n",
    "display(synthetic_commodities_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = output_dir / \"consolidated_data_export.xlsx\"\n",
    "logger.info(f\"Attempting to export data to: {excel_file_path}\")\n",
    "try:\n",
    "    with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "        if not portfolio_overview_df.empty:\n",
    "            portfolio_overview_df.to_excel(writer, sheet_name='PortfolioOverview', index=False)\n",
    "        if not sector_summary_df.empty:\n",
    "            sector_summary_df.to_excel(writer, sheet_name='SectorSummary', index=True)\n",
    "        if not country_summary_df.empty:\n",
    "            country_summary_df.to_excel(writer, sheet_name='CountrySummary', index=True)\n",
    "        if not companies_df.empty:\n",
    "            companies_df.to_excel(writer, sheet_name='CompaniesKB', index=False)\n",
    "        if not synthetic_equities_df.empty:\n",
    "            synthetic_equities_df.to_excel(writer, sheet_name='SyntheticEquities', index=False)\n",
    "        if not synthetic_commodities_df.empty:\n",
    "            synthetic_commodities_df.to_excel(writer, sheet_name='SyntheticCommodities', index=False)\n",
    "    logger.info(f\"Data successfully exported to {excel_file_path}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error exporting to Excel: {e}\")\n",
    "    logger.error(\"Please ensure 'openpyxl' is installed: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has generated the `consolidated_data_export.xlsx` file in the `output/` directory. It contains key tables from the credit risk analysis system. The previews above show the structure of each sheet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
